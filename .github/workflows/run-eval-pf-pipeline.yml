name: Test and Evaluate Prompts with Promptflow

on:
  workflow_dispatch:
  push:
    branches: [ main ]

env:
  GROUP: ${{ secrets.GROUP }}
  WORKSPACE: ${{ secrets.WORKSPACE }}
  SUBSCRIPTION: ${{ secrets.SUBSCRIPTION }}

jobs:
  login-run-eval:
    runs-on: ubuntu-latest

    steps:
    - name: Check out repo
      uses: actions/checkout@v3

    - name: Azure login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}

    - name: Set subscription
      run: az account set -s ${{ env.SUBSCRIPTION }}

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11.4"

    - name: Install promptflow client
      run: pip install -r promptflow/web-classification/requirements.txt

    - name: Run promptflow
      run: |
        pfazure run create \
          -f promptflow/web-classification/run.yml \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }} \
          --stream

    - name: Extract latest run name
      run: |
        RUN=$(pfazure run list \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }} \
          --output json | jq -r '.[0].name')
        echo "Detected RUN = $RUN"
        if [ -z "$RUN" ] || [ "$RUN" = "null" ]; then
          echo "❌ No run found — stopping pipeline"
          exit 1
        fi
        echo "RUN_NAME=$RUN" >> $GITHUB_ENV

    - name: Show PF run details
      run: |
        pfazure run show-details \
          --name ${{ env.RUN_NAME }} \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }}

    - name: Run evaluation
      run: |
        pfazure run create \
          -f promptflow/web-classification/run_evaluation.yml \
          --run ${{ env.RUN_NAME }} \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }} \
          --stream

    - name: Extract latest eval run name
      run: |
        EVAL=$(pfazure run list \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }} \
          --output json | jq -r '.[0].name')
        echo "Detected EVAL = $EVAL"
        if [ -z "$EVAL" ] || [ "$EVAL" = "null" ]; then
          echo "❌ No eval run found — stopping pipeline"
          exit 1
        fi
        echo "EVAL_RUN_NAME=$EVAL" >> $GITHUB_ENV

    - name: Show evaluation details
      run: |
        pfazure run show-details \
          --name ${{ env.EVAL_RUN_NAME }} \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }}

    - name: Export evaluation metrics
      run: |
        pfazure run show-metrics \
          --name ${{ env.EVAL_RUN_NAME }} \
          --subscription ${{ env.SUBSCRIPTION }} \
          -g ${{ env.GROUP }} \
          -w ${{ env.WORKSPACE }} \
          > promptflow/llmops-helper/eval_result.json

    - name: Upload eval metrics
      uses: actions/upload-artifact@v3
      with:
        name: eval-metrics
        path: promptflow/llmops-helper/eval_result.json
